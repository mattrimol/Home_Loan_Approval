{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_data = pd.read_csv('hmda_2017_ca_all-records_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# modeling imports\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing, pipeline, decomposition, compose\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "import imblearn.under_sampling\n",
    "import imblearn.over_sampling\n",
    "import xgboost as xgb\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store this to use later on if we want to dig more into interperetablity of results\n",
    "denials = all_data[['respondent_id', 'denial_reason_name_1', 'denial_reason_name_2', 'denial_reason_name_3']]\n",
    "\n",
    "all_data.drop([\n",
    "                'agency_name',\n",
    "                'agency_code',\n",
    "                'loan_type',\n",
    "                'property_type',\n",
    "                'loan_purpose',\n",
    "                'owner_occupancy',\n",
    "                'preapproval',\n",
    "                'action_taken',\n",
    "                'msamd',\n",
    "                'state_name',\n",
    "                'state_code',\n",
    "                'county_code',\n",
    "                'applicant_ethnicity',\n",
    "                'co_applicant_ethnicity',\n",
    "                'applicant_race_1',\n",
    "                'applicant_race_2',\n",
    "                'applicant_race_3',\n",
    "                'applicant_race_4',\n",
    "                'applicant_race_5',\n",
    "                'co_applicant_race_1',\n",
    "                'co_applicant_race_2',\n",
    "                'co_applicant_race_3',\n",
    "                'co_applicant_race_4',\n",
    "                'co_applicant_race_5',\n",
    "                'applicant_sex',\n",
    "                'co_applicant_sex',\n",
    "                'purchaser_type',\n",
    "                'denial_reason_1',\n",
    "                'denial_reason_2',\n",
    "                'denial_reason_3',\n",
    "                'denial_reason_name_1', #Stored in denials table\n",
    "                'denial_reason_name_2', #Stored in denials table\n",
    "                'denial_reason_name_3', #Stored in denials table\n",
    "                'hoepa_status',\n",
    "                'lien_status',\n",
    "                'edit_status',\n",
    "                'edit_status_name',\n",
    "                'sequence_number',\n",
    "                'application_date_indicator',\n",
    "                'rate_spread'],axis=1, inplace=True)\n",
    "\n",
    "#Only do this if single state and single year\n",
    "all_data.drop(['as_of_year', 'state_abbr'], axis=1, inplace=True)\n",
    "\n",
    "#Shortening some strings\n",
    "all_data.replace('One-to-four family dwelling (other than manufactured housing)',\n",
    "                 '1 to 4 family (excl. manufactured)', inplace=True)\n",
    "all_data.replace('Information not provided by applicant in mail, Internet, or telephone application',\n",
    "                 'Info not provided', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subjective Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likely too much complexity to go beyond two race listings\n",
    "all_data.drop(['applicant_race_name_3',\n",
    "               'applicant_race_name_4',\n",
    "               'applicant_race_name_5',\n",
    "               'co_applicant_race_name_3',\n",
    "               'co_applicant_race_name_4',\n",
    "               'co_applicant_race_name_5'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter down to applications accepted or denied (remove preapprovals and incompletes) and make binary\n",
    "acc_or_den_filter = (all_data['action_taken_name'] == 'Loan originated') |\\\n",
    "                    (all_data['action_taken_name'] == 'Application denied by financial institution')\n",
    "all_data = all_data[acc_or_den_filter]\n",
    "\n",
    "all_data['action_taken_name'].replace('Loan originated', 0, inplace=True)\n",
    "all_data['action_taken_name'].replace('Application denied by financial institution', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping all the entires where we don't have census data\n",
    "all_data = all_data[all_data['population'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping where loan_amount_000s is na\n",
    "all_data = all_data[all_data['loan_amount_000s'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.drop(['county_name', #Too many\n",
    "               'census_tract_number', #Too many\n",
    "               'purchaser_type_name',\n",
    "               'hoepa_status_name', #Most are not HOEPA\n",
    "               'lien_status_name', #Probably exclude since vast majority are in one category\n",
    "              ], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unreported incomes seem to have similar loan amounts as reported incomes\n",
    "# Droping nulls for now, but consider filling with median. Probably big enough sample to just drop though.\n",
    "all_data = all_data[all_data['applicant_income_000s'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null location for Metropolitan Statistical Area/Metropolitan Division calling 'Other'\n",
    "all_data.loc[all_data['msamd_name'] == np.nan, 'msamd_name'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping multifamily dwellings\n",
    "multifamily = all_data['property_type_name'] == 'Multifamily dwelling'\n",
    "all_data = all_data.drop(all_data[multifamily].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to exclude huge purchases and really small ones\n",
    "# Magic numbers here consider review\n",
    "loan_amt_filter = (all_data['loan_amount_000s'] > 25) &\\\n",
    "                  (all_data['loan_amount_000s'] < 20000)\n",
    "all_data = all_data[loan_amt_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary column, has coapplicant?\n",
    "def has_coapp(row):\n",
    "    if row['co_applicant_sex_name'] == 'No co-applicant':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "all_data['has_coapplicant'] = all_data.apply(lambda row: has_coapp(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 if backed by ANY federal agency\n",
    "def fed_insured(row):\n",
    "    if row['loan_type_name'] == 'Conventional':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "all_data['fed_insured'] = all_data.apply(lambda row: fed_insured(row), axis=1)\n",
    "all_data.drop('loan_type_name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan amount / Income\n",
    "all_data['loan_amount/applicant_income'] = all_data['loan_amount_000s']/all_data['applicant_income_000s']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_cols(df):\n",
    "    '''Print vertical list so you can paste into excel and make notes'''\n",
    "    for col in df.columns:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_feature(df, feature):\n",
    "    if is_numeric_dtype(df[feature]):\n",
    "        plt.hist(df[feature])\n",
    "    else:\n",
    "        print(df[feature].value_counts())\n",
    "        ((df[feature].value_counts() / len(df[feature]))*100).sort_values().plot(kind = 'barh')\n",
    "        plt.xticks(np.arange(0, 100, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_df(df, features_list):\n",
    "    return df[features_list + ['action_taken_name']].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count in all_data['action_taken_name'].value_counts():\n",
    "    print(count/len(all_data['action_taken_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_feature(all_data, 'agency_abbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_cols(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose features and make a dataframe with those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple bare bones model\n",
    "features_1 = ['applicant_income_000s', 'fed_insured']\n",
    "model1 = create_model_df(all_data, features_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throw more at it\n",
    "features_2 = ['loan_purpose_name',\n",
    "              'owner_occupancy_name',\n",
    "              'loan_amount_000s',\n",
    "              'applicant_race_name_1',\n",
    "              'applicant_income_000s',\n",
    "              'population',\n",
    "              'minority_population',\n",
    "              'hud_median_family_income',\n",
    "              'tract_to_msamd_income',\n",
    "              'has_coapplicant',\n",
    "              'fed_insured']\n",
    "model2 = create_model_df(all_data, features_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_3 = ['loan_purpose_name', 'owner_occupancy_name', 'loan_amount/applicant_income', 'tract_to_msamd_income']\n",
    "model3 = create_model_df(all_data, features_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_4 = ['agency_abbr',\n",
    "              'property_type_name',\n",
    "              'loan_purpose_name',\n",
    "              'owner_occupancy_name',\n",
    "              #'loan_amount_000s',\n",
    "              'msamd_name', #Going to be a lot of these\n",
    "              'applicant_ethnicity_name',\n",
    "              'applicant_race_name_1',\n",
    "              'applicant_sex_name',\n",
    "              #'applicant_income_000s',\n",
    "              'population',\n",
    "              'minority_population',\n",
    "              #'hud_median_family_income', #probably shouldn't include with tract_to_msand_income\n",
    "              'tract_to_msamd_income',\n",
    "              #'number_of_owner_occupied_units',\n",
    "              #'number_of_1_to_4_family_units',\n",
    "              'has_coapplicant',\n",
    "              'fed_insured',\n",
    "              'loan_amount/applicant_income']\n",
    "model4 = create_model_df(all_data, features_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take out any features that shouldn't actually have an effect (assume banks are not discriminating unfairly)\n",
    "features_5 = ['agency_abbr',\n",
    "              'property_type_name',\n",
    "              'loan_purpose_name',\n",
    "              'owner_occupancy_name',\n",
    "              #'loan_amount_000s',\n",
    "              #'msamd_name', #Going to be a lot of these\n",
    "              #'applicant_ethnicity_name',\n",
    "              #'applicant_race_name_1',\n",
    "              #'applicant_sex_name',\n",
    "              #'applicant_income_000s',\n",
    "              #'population',\n",
    "              #'minority_population',\n",
    "              #'hud_median_family_income', #probably shouldn't include with tract_to_msand_income\n",
    "              'tract_to_msamd_income',\n",
    "              #'number_of_owner_occupied_units',\n",
    "              #'number_of_1_to_4_family_units',\n",
    "              'has_coapplicant',\n",
    "              'fed_insured',\n",
    "              'loan_amount/applicant_income']\n",
    "model5 = create_model_df(all_data, features_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another simple model\n",
    "features_6 = [#'agency_abbr',\n",
    "              #'property_type_name',\n",
    "              #'loan_purpose_name',\n",
    "              #'owner_occupancy_name',\n",
    "              #'loan_amount_000s',\n",
    "              'msamd_name', #Going to be a lot of these\n",
    "              #'applicant_ethnicity_name',\n",
    "              #'applicant_race_name_1',\n",
    "              #'applicant_sex_name',\n",
    "              #'applicant_income_000s',\n",
    "              'population',\n",
    "              #'minority_population',\n",
    "              #'hud_median_family_income', #probably shouldn't include with tract_to_msand_income\n",
    "              'tract_to_msamd_income',\n",
    "              #'number_of_owner_occupied_units',\n",
    "              #'number_of_1_to_4_family_units',\n",
    "              #'has_coapplicant',\n",
    "              'fed_insured',\n",
    "              'loan_amount/applicant_income']\n",
    "model6 = create_model_df(all_data, features_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_7 = ['loan_purpose_name',\n",
    "              'msamd_name',\n",
    "              'fed_insured',\n",
    "              'loan_amount/applicant_income']\n",
    "model7 = create_model_df(all_data, features_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_splits(df):\n",
    "    '''Makes X_train, X_test, y_train_y_test given a data frame with features and action_taken_name as y.\n",
    "    Use this to make sure we don't mess up getting data from the wrong df'''\n",
    "    return train_test_split(df[np.setdiff1d(df.columns, ['action_taken_name'])],\n",
    "                                          df['action_taken_name'],\n",
    "                                          test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr1, X_te1, y_tr1, y_te1 = make_splits(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr2, X_te2, y_tr2, y_te2 = make_splits(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr3, X_te3, y_tr3, y_te3 = make_splits(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr4, X_te4, y_tr4, y_te4 = make_splits(model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr5, X_te5, y_tr5, y_te5 = make_splits(model5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr6, X_te6, y_tr6, y_te6 = make_splits(model6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr7, X_te7, y_tr7, y_te7 = make_splits(model7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_columns(X_train, X_test):\n",
    "    num_cols = []\n",
    "    cat_cols = []\n",
    "    \n",
    "    #This is a list that will be the dummy column to drop (it will be the one with the lowest value count)\n",
    "    drop_dummy_cols = []\n",
    "    \n",
    "    # Create the column lists from X_train and then apply the procedure to X_train and X_test\n",
    "    for feature in X_train.columns:\n",
    "        if type(all_data[feature].iloc[0]) == str:\n",
    "            cat_cols.append(feature) # Creating the list of columns that are categorical\n",
    "\n",
    "            # Gets the category name with the lowest count (this will be the dummy column we drop)\n",
    "            min_cat = all_data[feature].value_counts().keys()[-1]\n",
    "\n",
    "            drop_dummy_cols.append(feature + '_' + min_cat) #string convention from pd.get_dummies\n",
    "\n",
    "        else:\n",
    "            num_cols.append(feature) #Columns that will get the standard scaler\n",
    "    \n",
    "    \n",
    "    std_scale = preprocessing.StandardScaler()\n",
    "    for column in X_train.columns:\n",
    "        if column in num_cols:\n",
    "            #standard scaling the numerical columns\n",
    "            X_train[column] = std_scale.fit_transform(np.array(X_train[column]).reshape(-1, 1))\n",
    "            X_test[column] = std_scale.fit_transform(np.array(X_test[column]).reshape(-1, 1))\n",
    "    \n",
    "    #Get dummies for the categoricals and drop the one with the lowest value count\n",
    "    X_train = pd.get_dummies(X_train)\n",
    "    X_test = pd.get_dummies(X_test)\n",
    "    X_train.drop(drop_dummy_cols, axis=1, inplace=True)\n",
    "    X_test.drop(drop_dummy_cols, axis=1, inplace=True)\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sns.pairplot(model3.sample(frac=0.3, replace=True, random_state=1), hue='action_taken_name');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sorted(metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20% is denials (action_taken_name = 1)\n",
    "# 80% is loan originated\n",
    "def under_sample_bal(X_train, y_train):\n",
    "    '''pass in training data and return X_train_rs, y_train_rs'''\n",
    "    n_pos = np.sum(y_train == 1)\n",
    "    n_neg = np.sum(y_train == 0)\n",
    "    ratio = {1 : int(n_pos), 0 : int(n_neg/4)} \n",
    "\n",
    "    ROS = imblearn.under_sampling.RandomUnderSampler(sampling_strategy = ratio, random_state=42) \n",
    "    return ROS.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(X_train, y_train, model, display_results=True, eval_metric=None, threshold=None):\n",
    "    '''\n",
    "    Cross validates and scores a model. Automattically standardizes numerical features, dummifies categoricals,\n",
    "    and rebalances data with undersampling function.\n",
    "    Inputs:\n",
    "    X_train: Full X_train data\n",
    "    y_train: Full y_train data\n",
    "    model: empty model such as RandomForestClassifier(). Specify hyperparameters if necessary.\n",
    "    display_results: If True, function will print out averae metrics across K Folds\n",
    "    eval_metric: Input string that corresponds to a metric in scores dict (see below). If specified,\n",
    "    the function will return a value for that metric's average. Can be used to cross validate to optimize for a metric.\n",
    "    '''\n",
    "      \n",
    "    \n",
    "    scores = {'accuracy_train': [], 'accuracy': [], 'recall': [], 'roc_auc': [],\n",
    "              'f1': [], 'precision': [],}\n",
    "    sfk = StratifiedKFold(n_splits=5)\n",
    "    \n",
    "    for train_index, test_index in sfk.split(X_train, y_train):\n",
    "        #create a train/val set for a split\n",
    "        X_tr, X_val = X_train.iloc[train_index].copy(), X_train.iloc[test_index].copy()\n",
    "        y_tr, y_val = y_train.iloc[train_index].copy(), y_train.iloc[test_index].copy()\n",
    "        \n",
    "        #preprocess X sets\n",
    "        X_tr_proc, X_val_proc = preprocess_columns(X_tr, X_val)\n",
    "\n",
    "        #Balance pos/neg class with undersampling\n",
    "        X_tr_rs, y_tr_rs = under_sample_bal(X_tr_proc, y_tr)\n",
    "        #print(np.sum(y_tr_rs == 1), np.sum(y_tr_rs == 0)) ###Checker to make sure balanced right\n",
    "        \n",
    "        #fit to train\n",
    "        model.fit(X_tr_rs, y_tr_rs)\n",
    "        if threshold:\n",
    "            y_proba_train = model.predict_proba(X_tr_proc)\n",
    "            y_pred_train = (y_proba_train[:,1] >= threshold).astype('int')\n",
    "            \n",
    "            #Validation Data\n",
    "            y_pred_proba = model.predict_proba(X_val_proc)\n",
    "            y_pred = (y_pred_proba[:,1] >= threshold).astype('int')\n",
    "        else:\n",
    "            y_pred_train = model.predict(X_tr_proc)\n",
    "            y_pred = model.predict(X_val_proc)\n",
    "        \n",
    "        # Score\n",
    "        accuracy_train = metrics.accuracy_score(y_tr, y_pred_train)\n",
    "        scores['accuracy_train'].append(accuracy_train)\n",
    "        accuracy = metrics.accuracy_score(y_val, y_pred)\n",
    "        scores['accuracy'].append(accuracy)\n",
    "        \n",
    "        recall = metrics.recall_score(y_val, y_pred)\n",
    "        scores['recall'].append(recall)\n",
    "        \n",
    "        roc_auc = metrics.roc_auc_score(y_val, y_pred)\n",
    "        scores['roc_auc'].append(roc_auc)       \n",
    "        \n",
    "        f1 = metrics.f1_score(y_val, y_pred)\n",
    "        scores['f1'].append(f1)\n",
    "        \n",
    "        precision = metrics.precision_score(y_val, y_pred)\n",
    "        scores['precision'].append(precision)\n",
    "    \n",
    "    if display_results:\n",
    "        print(type(model))\n",
    "        print('Means:')\n",
    "        for metric in scores:\n",
    "            mean = np.mean(scores[metric])\n",
    "            all_scores = list(np.around(np.array(scores[metric]),2))\n",
    "            print('{:<20s},{:>15.2f},  {}'.format(metric, mean, all_scores))\n",
    "            \n",
    "    if eval_metric:\n",
    "        return np.mean(scores[eval_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic model hyperparameters\n",
    "solver = 'liblinear'\n",
    "max_iter = 200\n",
    "\n",
    "def log_cross_val(X_train, y_train):\n",
    "    '''Cross validates a logistic model on many C values and returns optimal C'''\n",
    "    C_results = defaultdict()\n",
    "\n",
    "    for C in [0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 10.0, 100, 1000, 10000]:\n",
    "        logreg = LogisticRegression(C=C, solver=solver, max_iter=max_iter)\n",
    "        eval_result = cross_validate(X_train, y_train, logreg, display_results=False, eval_metric='roc_auc')\n",
    "        C_results[eval_result] = C\n",
    "\n",
    "    best_score = max(C_results.keys())\n",
    "    optimal_C = C_results[best_score]\n",
    "\n",
    "\n",
    "    logreg = LogisticRegression(C=optimal_C, solver=solver, max_iter=max_iter)\n",
    "    cross_validate(X_train, y_train, logreg)\n",
    "    \n",
    "    print(f'Optimal C: {optimal_C}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#log_cross_val(X_tr1, y_tr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#log_cross_val(X_tr2, y_tr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#log_cross_val(X_tr3, y_tr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_cross_val(X_tr4, y_tr4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_cross_val(X_tr5, y_tr5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_cross_val(X_tr6, y_tr6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_cross_val(X_tr7, y_tr7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Classifier Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr1, y_tr1, rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr2, y_tr2, rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr3, y_tr3, rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr4, y_tr4, rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr5, y_tr5, rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cross_validate(X_tr6, y_tr6, rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr7, y_tr7, rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc2 = RandomForestClassifier(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr2, y_tr2, rfc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr2, y_tr2, rfc2, threshold=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr4, y_tr4, rfc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr4, y_tr4, rfc2, threshold=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc3 = RandomForestClassifier(n_estimators=10, max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr2, y_tr2, rfc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr2, y_tr2, rfc3, threshold=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr4, y_tr4, rfc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr4, y_tr4, rfc3, threshold=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boosted Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = xgb.XGBClassifier( \n",
    "                       n_estimators=30000, #arbitrary large number\n",
    "                       max_depth=3,\n",
    "                       objective=\"reg:squarederror\",\n",
    "                       learning_rate=.1, \n",
    "                       subsample=1,\n",
    "                       min_child_weight=1,\n",
    "                       colsample_bytree=.8\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cross_validate(X_tr2, y_tr2, gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr2, y_tr2, gbm, threshold=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr4, y_tr4, gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr4, y_tr4, gbm, threshold=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm2 = xgb.XGBClassifier( \n",
    "                       n_estimators=100,\n",
    "                       max_depth=3,\n",
    "                       objective=\"reg:squarederror\",\n",
    "                       learning_rate=.1, \n",
    "                       subsample=1,\n",
    "                       min_child_weight=1,\n",
    "                       colsample_bytree=.8\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr2, y_tr2, gbm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr2, y_tr2, gbm2, threshold=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr4, y_tr4, gbm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(X_tr4, y_tr4, gbm2, threshold=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test(X_train, X_test, y_train, y_test, model):    \n",
    "    #preprocess X sets\n",
    "    X_train_proc, X_test_proc = preprocess_columns(X_train, X_test)\n",
    "    #Balance pos/neg class with undersampling\n",
    "    X_train_rs, y_train_rs = under_sample_bal(X_train_proc, y_train)\n",
    "    #fit to train\n",
    "    model.fit(X_train_rs, y_train_rs)\n",
    "    #generate predictions\n",
    "    y_pred = model.predict(X_test_proc)\n",
    "    \n",
    "    # Now that everything is transformed use:\n",
    "        # X_train_rs\n",
    "        # X_test_proc\n",
    "        # y_train_rs\n",
    "        # y_test       \n",
    "\n",
    "    # Score test data\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "    print('Important:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Recall: {recall}')\n",
    "\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, model.predict_proba(X_test_proc)[:,1])\n",
    "    plt.plot(fpr, tpr,lw=2)\n",
    "    plt.plot([0,1],[0,1],c='violet',ls='--')\n",
    "    plt.xlim([-0.05,1.05])\n",
    "    plt.ylim([-0.05,1.05])\n",
    "\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve');\n",
    "    print(\"ROC AUC score = \", metrics.roc_auc_score(y_test, model.predict_proba(X_test_proc)[:,1]))\n",
    "    \n",
    "    #for feature, coef in X_train_rs.columns, model.coef_:\n",
    "        #print('{:<20s}{:>15.2f}'.format(feature, coef))\n",
    "    try:\n",
    "        print(model.coef_)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    print('\\nLess Important:')\n",
    "    print(f'Precision: {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(X_tr4, X_te4, y_tr4, y_te4, rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
